{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento de uam rede CNN para classificação de imagens de mamografia\n",
    "\n",
    "# Importando as bibliotecas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados\n",
    "\n",
    "WORK_DIR = os.getcwd()\n",
    "UP_DIR = os.path.dirname(WORK_DIR)\n",
    "UP_DIR = os.path.dirname(UP_DIR)\n",
    "DATADIR = os.path.join(UP_DIR, 'data', 'cbis-ddsm')\n",
    "CATEGORIES = ['BENIGN', 'MALIGNANT']\n",
    "\n",
    "# csv com os dados das imagens\n",
    "df_train = pd.read_csv(os.path.join(DATADIR, 'Train', 'clean_mass_train_description2.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATADIR, 'Test', 'clean_mass_test_description2.csv'))\n",
    "\n",
    "# Verificando os dados\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "# Verificando o tamanho dos dados\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(df_train['pathology'].value_counts())\n",
    "print(df_test['pathology'].value_counts())\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(df_train['breast_density'].value_counts())\n",
    "print(df_test['breast_density'].value_counts())\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(df_train['left or right breast'].value_counts())\n",
    "print(df_test['left or right breast'].value_counts())\n",
    "\n",
    "\n",
    "# Exclude Begnin withouth callback\n",
    "df_train = df_train[df_train['pathology'] != 'BENIGN_WITHOUT_CALLBACK']\n",
    "df_test = df_test[df_test['pathology'] != 'BENIGN_WITHOUT_CALLBACK']\n",
    "\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(df_train['pathology'].value_counts())\n",
    "print(df_test['pathology'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports para processamento dos dados \n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Preparando os dados\n",
    "\n",
    "CATEGORIES = ['BENIGN', 'MALIGNANT']\n",
    "IMG_SIZE = 224\n",
    "def create_training_data(df, img_size, categories, datadir):\n",
    "    training_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            img_array = plt.imread(os.path.join(datadir, row['image file path']),0)\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            # Normalizing the data\n",
    "            # To Numpy array\n",
    "            new_array = np.array(new_array)\n",
    "            training_data.append([new_array, categories.index(row['pathology'])])\n",
    "            # Benign = 0, Malignant = 1\n",
    "                        \n",
    "\n",
    "            print(index)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    return training_data\n",
    "\n",
    "train_data = create_training_data(df_train, IMG_SIZE, CATEGORIES, os.path.join(DATADIR, 'Train', 'Train'))\n",
    "testing_data = create_training_data(df_test, IMG_SIZE, CATEGORIES, os.path.join(DATADIR, 'Test', 'Test'))\n",
    "\n",
    "# Verificando o tamanho dos dados\n",
    "print(len(train_data))\n",
    "print(len(testing_data))\n",
    "\n",
    "# Verificando os dados\n",
    "print(train_data[0])\n",
    "print(testing_data[0])\n",
    "\n",
    "# Embaralhando os dados\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(testing_data)\n",
    "\n",
    "\n",
    "# Separando os dados\n",
    "X_train = []\n",
    "y_train = []\n",
    "for features, label in train_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for features, label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "\n",
    "# Convertendo para numpy array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de media e desvio padrão dos dados\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(np.mean(X_train))\n",
    "print(np.std(X_train))\n",
    "print(np.mean(X_test))\n",
    "print(np.std(X_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge data and separate in train and test\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Métricas de media e desvio padrão dos dados\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(np.mean(X_train))\n",
    "print(np.std(X_train))\n",
    "print(np.mean(X_test))\n",
    "print(np.std(X_test))\n",
    "\n",
    "#print dtypes\n",
    "print(X_train.dtype)\n",
    "print(X_test.dtype)\n",
    "print(X_train[0].dtype)\n",
    "\n",
    "# Equalizing histogram\n",
    "def equalize_hist(img):\n",
    "    # Convert to uint8\n",
    "    img = (img*255).astype(np.uint8)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "X_test_eq = []\n",
    "for img in X_test:\n",
    "    X_test_eq.append(equalize_hist(img))\n",
    "\n",
    "X_train_eq = []\n",
    "for img in X_train:\n",
    "    X_train_eq.append(equalize_hist(img))\n",
    "\n",
    "X_train_eq = np.array(X_train_eq)\n",
    "X_test_eq = np.array(X_test_eq)\n",
    "\n",
    "X_train = X_train_eq\n",
    "X_test = X_test_eq\n",
    "\n",
    "\n",
    "# To 3 channels\n",
    "X_train_o = np.stack((X_train,)*3, axis=-1)\n",
    "X_test_o = np.stack((X_test,)*3, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning GPU memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Teste com modelo pre-treinado VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "# Pre processing layers\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Pre processamento\n",
    "X_train = preprocess_input(X_train_o)\n",
    "X_test = preprocess_input(X_test_o)\n",
    "\n",
    "\n",
    "# Carregando o modelo\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "\n",
    "# Congelando as camadas\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Head do modelo\n",
    "x = vgg16.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# LR Scheduler function\n",
    "# Linear warmup, then cosine decay\n",
    "def lrate(epoch):\n",
    "    # Warmup\n",
    "    wrmup = 20\n",
    "    peak = 0.00005\n",
    "    lenght = 60\n",
    "    if epoch < wrmup:\n",
    "        return peak * (epoch+1) / wrmup\n",
    "    else:\n",
    "        return peak/2 * (1 + np.cos((epoch-wrmup) / (lenght -wrmup) * np.pi))\n",
    "    \n",
    "# PLot the learning rate for the first 100 epochs\n",
    "lrs = [lrate(i) for i in range(60)]\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "\n",
    "# Callbacks\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(lrate, verbose=1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Otimizador usando callback\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "# Modelo\n",
    "model = Model(inputs=vgg16.input, outputs=preds)\n",
    "\n",
    "# Visualizando o modelo\n",
    "model.summary()\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_train, y_train, epochs=60, validation_data=(X_test, y_test), callbacks=[lrate, early_stopping, checkpoint])\n",
    "\n",
    "\n",
    "# Avaliando o modelo\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "# Plotando a acurácia\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotando a perda\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predições\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "#plot \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com modelo pre-treinado RESNET50\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Data\n",
    "\n",
    "# Processamento\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def train_model_resnet50(model\n",
    "    # Pre processamento\n",
    "    X_train = preprocess_input(X_train_o)\n",
    "    X_test = preprocess_input(X_test_o)\n",
    "\n",
    "    # Carregando o modelo\n",
    "    resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    # Congelando as camadas\n",
    "    for layer in resnet50.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Head do modelo\n",
    "    x = resnet50.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # LR Scheduler function\n",
    "    # Linear warmup, then cosine decay\n",
    "    def lrate(epoch):\n",
    "        # Warmup\n",
    "        wrmup = 10\n",
    "        peak = 0.00005\n",
    "        stay = 10\n",
    "        lenght_decay = 60\n",
    "        if epoch < wrmup:\n",
    "            return peak * (epoch+1) / wrmup\n",
    "        elif epoch < wrmup + stay:\n",
    "            return peak\n",
    "        else:\n",
    "            return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "        \n",
    "    # PLot the learning rate for the first 100 epochs\n",
    "    lrs = [lrate(i) for i in range(60)]\n",
    "    plt.plot(lrs)\n",
    "    plt.show()\n",
    "\n",
    "    # Callbacks\n",
    "    lrate = tf.keras.callbacks.LearningRateScheduler(lrate, verbose=1)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    # Otimizador usando callback\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "    # Modelo\n",
    "    model = Model(inputs=resnet50.input, outputs=preds)\n",
    "\n",
    "    # Visualizando o modelo\n",
    "    model.summary()\n",
    "\n",
    "    # Compilando o modelo\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Treinando o modelo\n",
    "    history = model.fit(X_train, y_train, epochs=60, validation_data=(X_test, y_test), callbacks=[lrate, early_stopping, checkpoint])\n",
    "\n",
    "    # Avaliando o modelo\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "\n",
    "    # Plotando a acurácia\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotando a perda\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Predições\n",
    "    predictions = model.predict(X_test)\n",
    "    print(predictions)\n",
    "\n",
    "    # Save history in csv'\n",
    "    da\n",
    "    training_info = 'resnet50+\n",
    "    filename = 'history-'+training_info+'.csv'\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_df.to_csv('history.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avaliando o modelo\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "# Plotando a acurácia\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotando a perda\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predições\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com modelo pre-treinado MOBILENETV2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Processamento\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Pre processamento\n",
    "X_train = preprocess_input(X_train_o)\n",
    "X_test = preprocess_input(X_test_o)\n",
    "\n",
    "\n",
    "# Carregando o modelo\n",
    "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Congelando as camadas\n",
    "for layer in mobilenetv2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Head do modelo\n",
    "x = mobilenetv2.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# LR Scheduler function\n",
    "# Linear warmup, then cosine decay\n",
    "def lrate(epoch):\n",
    "    # Warmup\n",
    "    wrmup = 10\n",
    "    peak = 0.00005\n",
    "    stay = 10\n",
    "    lenght_decay = 60\n",
    "    if epoch < wrmup:\n",
    "        return peak * (epoch+1) / wrmup\n",
    "    elif epoch < wrmup + stay:\n",
    "        return peak\n",
    "    else:\n",
    "        return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "    \n",
    "# PLot the learning rate for the first 100 epochs\n",
    "lrs = [lrate(i) for i in range(60)]\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "\n",
    "# Callbacks\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(lrate, verbose=1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Otimizador usando callback\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "# Modelo\n",
    "model = Model(inputs=mobilenetv2.input, outputs=preds)\n",
    "\n",
    "# Visualizando o modelo\n",
    "model.summary()\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_train, y_train, epochs=60, validation_data=(X_test, y_test), callbacks=[lrate, early_stopping, checkpoint])\n",
    "\n",
    "# Avaliando o modelo\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdgaete/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 181\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m peak\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mcos((epoch\u001b[38;5;241m-\u001b[39mwrmup) \u001b[38;5;241m/\u001b[39m (  lenght_decay \u001b[38;5;241m-\u001b[39m stay \u001b[38;5;241m-\u001b[39m wrmup) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[0;32m--> 181\u001b[0m     train_model_resnet50(\u001b[43mX_train\u001b[49m, X_test, y_train, y_test, X_test, y_test, lrate, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet50-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# VGG16\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import models \n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "# Vit models\n",
    "from vit_keras import vit\n",
    "from vit_keras import utils as vit_utils\n",
    "\n",
    "# Pre processing layers\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_input_mobilenetv2 \n",
    "\n",
    "\n",
    "# Function for bulk training \n",
    "# Function for resnet50\n",
    "def train_model(X_train, X_test, y_train, y_test, X_val, y_val , training_info, model, callbacks , optimizer, loss, metrics, epochs):\n",
    "   \n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    # Train model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=callbacks)\n",
    "    # Save history in csv\n",
    "    filename = 'history-'+training_info+'.csv'\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_df.to_csv(filename, index=False)\n",
    "    \n",
    "def train_model_resnet50(X_train, X_test, y_train, y_test, X_val, y_val , lrfunc, training_info , epochs):\n",
    "   # Model\n",
    "    resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    # Congelando as camadas\n",
    "    for layer in resnet50.layers:\n",
    "        layer.trainable = False\n",
    "    # Head do modelo\n",
    "    x = resnet50.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    # Modelo\n",
    "    model = Model(inputs=resnet50.input, outputs=preds)\n",
    "    \n",
    "    # Pre processamento\n",
    "    X_train = preprocess_input_resnet50(X_train)\n",
    "    X_test = preprocess_input_resnet50(X_test)\n",
    "    X_val = preprocess_input_resnet50(X_val)\n",
    "    # Otimizador usando callback\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "\n",
    "    # LR Scheduler\n",
    "    lrate = tf.keras.callbacks.LearningRateScheduler(lrfunc, verbose=1)\n",
    "    # Early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    # Train model\n",
    "    train_model(X_train, X_test, y_train, y_test, X_val, y_val, training_info, model, [lrate, early_stopping, checkpoint], sgd, 'binary_crossentropy', ['accuracy'], epochs)\n",
    "\n",
    "\n",
    "def train_model_vgg16(X_train, X_test, y_train, y_test, X_val, y_val , lrfunc, training_info , epochs):\n",
    "   # Model\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    # Congelando as camadas\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    # Head do modelo\n",
    "    x = vgg16.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    # Modelo\n",
    "    model = Model(inputs=vgg16.input, outputs=preds)\n",
    "    \n",
    "    # Pre processamento\n",
    "    X_train = preprocess_input_vgg16(X_train)\n",
    "    X_test = preprocess_input_vgg16(X_test)\n",
    "    X_val = preprocess_input_vgg16(X_val)\n",
    "\n",
    "    # Otimizador usando callback\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "\n",
    "    # LR Scheduler\n",
    "    lrate = tf.keras.callbacks.LearningRateScheduler(lrfunc, verbose=1)\n",
    "    # Early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    # Train model\n",
    "    train_model(X_train, X_test, y_train, y_test, X_val, y_val, training_info, model, [lrate, early_stopping, checkpoint], sgd, 'binary_crossentropy', ['accuracy'], epochs)\n",
    "\n",
    "def train_model_mobilenetv2(X_train, X_test, y_train, y_test, X_val, y_val , lrfunc, training_info , epochs):\n",
    "   # Model\n",
    "    mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    # Congelando as camadas\n",
    "    for layer in mobilenetv2.layers:\n",
    "        layer.trainable = False\n",
    "    # Head do modelo\n",
    "    x = mobilenetv2.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    # Modelo\n",
    "    model = Model(inputs=mobilenetv2.input, outputs=preds)\n",
    "    \n",
    "    # Pre processamento\n",
    "    X_train = preprocess_input_mobilenetv2(X_train)\n",
    "    X_test = preprocess_input_mobilenetv2(X_test)\n",
    "    X_val = preprocess_input_mobilenetv2(X_val)\n",
    "\n",
    "    # Otimizador usando callback\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "\n",
    "    # LR Scheduler\n",
    "    lrate = tf.keras.callbacks.LearningRateScheduler(lrfunc, verbose=1)\n",
    "    # Early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    # Train model\n",
    "    train_model(X_train, X_test, y_train, y_test, X_val, y_val, training_info, model, [lrate, early_stopping, checkpoint], sgd, 'binary_crossentropy', ['accuracy'], epochs)\n",
    "\n",
    "def train_model_vit(X_train, X_test, y_train, y_test, X_val, y_val , lrfunc, training_info , epochs):\n",
    "    # Model\n",
    "    vit_model = vit.vit_b16(\n",
    "    image_size = IMG_SIZE,\n",
    "    activation = 'sigmoid',\n",
    "    pretrained = True,\n",
    "    include_top = True,\n",
    "    pretrained_top = False,\n",
    "    classes = 2\n",
    "    )\n",
    "\n",
    "    # Pre processamento\n",
    "    X_train = vit.preprocess_inputs(X_train)\n",
    "    X_test = vit.preprocess_inputs(X_test)\n",
    "    X_val = vit.preprocess_inputs(X_val)\n",
    "\n",
    "    \n",
    "    #Only the head is trained\n",
    "    vit_model.trainable = True\n",
    "    for layer in vit_model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "    # Otimizador usando callback\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "    # LR Scheduler\n",
    "    lrate = tf.keras.callbacks.LearningRateScheduler(lrfunc, verbose=1)\n",
    "    # Early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    # Train model\n",
    "    train_model(X_train, X_test, y_train, y_test, X_val, y_val, training_info, vit_model, [lrate, early_stopping, checkpoint], sgd, 'binary_crossentropy', ['accuracy'], epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train 10 models with different lr peaks\n",
    "\n",
    "# Resnet50\n",
    "for i in range(10):\n",
    "\n",
    "    def lrate(epoch):\n",
    "        # Warmup\n",
    "        wrmup = 20\n",
    "        peak = 0.0001 + 0.000005*(i-5)\n",
    "        stay = 0\n",
    "        lenght_decay = 60\n",
    "        if epoch < wrmup:\n",
    "            return peak * (epoch+1) / wrmup\n",
    "        elif epoch < wrmup + stay:\n",
    "            return peak\n",
    "        else:\n",
    "            return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "\n",
    "    train_model_resnet50(X_train, X_test, y_train, y_test, X_test, y_test, lrate, 'resnet50-'+str(i), 60)\n",
    "\n",
    "# VGG16\n",
    "for i in range(10):\n",
    "\n",
    "    def lrate(epoch):\n",
    "        # Warmup\n",
    "        wrmup = 20\n",
    "        peak = 0.00005*(i+1)\n",
    "        stay = 10\n",
    "        lenght_decay = 60\n",
    "        if epoch < wrmup:\n",
    "            return peak * (epoch+1) / wrmup\n",
    "        elif epoch < wrmup + stay:\n",
    "            return peak\n",
    "        else:\n",
    "            return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "\n",
    "    train_model_vgg16(X_train, X_test, y_train, y_test, X_test, y_test, lrate, 'vgg16-'+str(i), 60)\n",
    "\n",
    "# MobileNetV2\n",
    "for i in range(10):\n",
    "\n",
    "    def lrate(epoch):\n",
    "        # Warmup\n",
    "        wrmup = 20\n",
    "        peak = 0.00005*(i+1)\n",
    "        stay = 10\n",
    "        lenght_decay = 60\n",
    "        if epoch < wrmup:\n",
    "            return peak * (epoch+1) / wrmup\n",
    "        elif epoch < wrmup + stay:\n",
    "            return peak\n",
    "        else:\n",
    "            return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "\n",
    "    train_model_mobilenetv2(X_train, X_test, y_train, y_test, X_test, y_test, lrate, 'mobilenetv2-'+str(i), 60)\n",
    "\n",
    "# ViT\n",
    "for i in range(10):\n",
    "\n",
    "    def lrate(epoch):\n",
    "        # Warmup\n",
    "        wrmup = 20\n",
    "        peak = 0.00005*(i+1)\n",
    "        stay = 10\n",
    "        lenght_decay = 60\n",
    "        if epoch < wrmup:\n",
    "            return peak * (epoch+1) / wrmup\n",
    "        elif epoch < wrmup + stay:\n",
    "            return peak\n",
    "        else:\n",
    "            return peak/2 * (1 + np.cos((epoch-wrmup) / (  lenght_decay - stay - wrmup) * np.pi))\n",
    "\n",
    "    train_model_vit(X_train, X_test, y_train, y_test, X_test, y_test, lrate, 'vit-'+str(i), 60)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
